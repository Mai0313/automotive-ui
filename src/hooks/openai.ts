import type {
  ChatCompletionMessageParam,
  ChatCompletionChunk,
} from "openai/resources";

import { OpenAI } from "openai";
import { Stream } from "openai/streaming";

import {
  getOpenAIApiKey,
  getOpenAIBaseUrl,
  getOpenAIModel,
  isOpenAIConfigured,
} from "../utils/env";

/**
 * Custom error class for OpenAI configuration issues
 */
class OpenAIConfigurationError extends Error {
  constructor(message: string) {
    super(message);
    this.name = "OpenAIConfigurationError";
  }
}

// Initialize the OpenAI client
const createClient = () => {
  if (!isOpenAIConfigured()) {
    const errorMsg = `ğŸš« [OpenAI] Configuration incomplete. Please check the following environment variables:
- EXPO_PUBLIC_OPENAI_API_KEY
- EXPO_PUBLIC_OPENAI_BASE_URL  
- EXPO_PUBLIC_OPENAI_MODEL`;

    console.error(errorMsg);
    throw new OpenAIConfigurationError("OpenAI configuration is incomplete");
  }

  const apiKey = getOpenAIApiKey()!;
  const baseURL = getOpenAIBaseUrl()!;

  return new OpenAI({
    apiKey,
    baseURL,
    dangerouslyAllowBrowser: true,
  });
};

// Export a chat completion function that supports both streaming and non-streaming
export async function chatCompletion({
  messages,
  onDelta,
  signal,
  stream = true,
}: {
  messages: ChatCompletionMessageParam[];
  onDelta?: (delta: string) => void;
  signal?: AbortSignal;
  stream?: boolean;
}): Promise<string | void> {
  try {
    if (!isOpenAIConfigured()) {
      const errorMsg =
        "ğŸš« [OpenAI Chat] Configuration incomplete. Please configure OpenAI environment variables to use chat functionality.";

      console.error(errorMsg);
      onDelta?.("âŒ OpenAI è¨­å®šä¸å®Œæ•´ï¼Œç„¡æ³•ä½¿ç”¨å°è©±åŠŸèƒ½ã€‚è«‹æª¢æŸ¥ç’°å¢ƒè®Šæ•¸è¨­å®šã€‚");

      return stream ? undefined : "";
    }

    const client = createClient();
    const model = getOpenAIModel()!;

    if (stream) {
      // Streaming mode
      const streamResponse = await client.chat.completions.create(
        {
          model,
          messages,
          stream: true,
        },
        { signal },
      );

      for await (const chunk of streamResponse as Stream<ChatCompletionChunk>) {
        const delta = chunk.choices?.[0]?.delta?.content;

        if (delta) onDelta?.(delta);
      }
    } else {
      // Non-streaming mode
      const completion = await client.chat.completions.create(
        {
          model,
          messages,
          stream: false,
        },
        { signal },
      );

      const content = completion.choices?.[0]?.message?.content || "";
      if (content && onDelta) onDelta(content);
      return content;
    }
  } catch (error) {
    if (error instanceof OpenAIConfigurationError) {
      console.error("ğŸš« [OpenAI Chat] Configuration error:", error.message);
      onDelta?.("âŒ OpenAI è¨­å®šéŒ¯èª¤ï¼Œè«‹æª¢æŸ¥ç’°å¢ƒè®Šæ•¸é…ç½®ã€‚");

      return stream ? undefined : "";
    }

    console.error("ğŸš« [OpenAI Chat] API error:", error);

    // æä¾›æ›´å‹å–„çš„éŒ¯èª¤è¨Šæ¯çµ¦ç”¨æˆ¶
    let userMessage = "âŒ å°è©±æœå‹™æš«æ™‚ç„¡æ³•ä½¿ç”¨";

    if (error instanceof Error) {
      if (
        error.message.includes("401") ||
        error.message.includes("Unauthorized")
      ) {
        userMessage = "âŒ API é‡‘é‘°ç„¡æ•ˆï¼Œè«‹æª¢æŸ¥è¨­å®š";
      } else if (
        error.message.includes("404") ||
        error.message.includes("Not Found")
      ) {
        userMessage = "âŒ æ¨¡å‹æˆ–ç«¯é»ä¸å­˜åœ¨ï¼Œè«‹æª¢æŸ¥è¨­å®š";
      } else if (
        error.message.includes("429") ||
        error.message.includes("Rate limit")
      ) {
        userMessage = "âŒ API è«‹æ±‚éæ–¼é »ç¹ï¼Œè«‹ç¨å¾Œå†è©¦";
      }
    }

    onDelta?.(userMessage);
    if (stream) {
      throw error;
    } else {
      return userMessage;
    }
  }
}
